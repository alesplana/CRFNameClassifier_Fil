{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-FIRST       0.88      0.85      0.87      2026\n",
      "      B-LAST       0.85      0.72      0.78      1990\n",
      "    B-MIDDLE       0.62      0.95      0.75      1932\n",
      "     I-FIRST       0.97      0.49      0.65      1084\n",
      "      I-LAST       0.00      0.00      0.00        35\n",
      "    I-MIDDLE       0.71      0.07      0.13        70\n",
      "\n",
      "    accuracy                           0.77      7137\n",
      "   macro avg       0.67      0.51      0.53      7137\n",
      "weighted avg       0.81      0.77      0.77      7137\n",
      "\n",
      "\n",
      "Top 10 most important features:\n",
      "word.length: -0.8361709610977037\n",
      "word.relative_position: -3.329575571424014\n",
      "BOS: -3.3648798337406056\n",
      "EOS: -3.470331912250785\n",
      "word.contains_comma: -3.4984262524764294\n",
      "prev_word.is_surname_indicator: -5.2873015309305895\n",
      "word=MAE: -5.832044239730096\n",
      "prev_word=DE: -6.053876180045353\n",
      "word=JOY: -6.080940287146721\n",
      "word.is_suffix: -6.208279709523323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/UDAmiel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/UDAmiel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/UDAmiel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/UDAmiel/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "\n",
    "df = pd.read_csv('../data/clean_x.csv', sep='|', header=0)\n",
    "df = df.head(10000)\n",
    "df.fillna('', inplace=True)\n",
    "df['last_name'] = df['1']\n",
    "df['first_name'] = df['A']\n",
    "df['middle_name'] = df['B']\n",
    "\n",
    "suffixes = {'JR', 'SR', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII'}\n",
    "surname_indicators = {'DE', 'DEL', 'DELA', 'DELOS', 'SAN', 'SANTA', 'SANTO'}\n",
    "\n",
    "def extract_features(tokens, index):\n",
    "    word = tokens[index]\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'word.length': len(word),\n",
    "        'word.relative_position': index / len(tokens),\n",
    "        'word.is_suffix': word in suffixes,\n",
    "        'word.is_surname_indicator': word in surname_indicators,\n",
    "        'word.contains_hyphen': '-' in word,\n",
    "        'word.contains_period': '.' in word,\n",
    "        'word.contains_comma': ',' in word,\n",
    "    }\n",
    "\n",
    "    if index > 0:\n",
    "        prev_word = tokens[index - 1]\n",
    "        features.update({\n",
    "            'prev_word': prev_word,\n",
    "            'prev_word.is_suffix': prev_word in suffixes,\n",
    "            'prev_word.is_surname_indicator': prev_word in surname_indicators,\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if index < len(tokens) - 1:\n",
    "        next_word = tokens[index + 1]\n",
    "        features.update({\n",
    "            'next_word': next_word,\n",
    "            'next_word.is_suffix': next_word in suffixes,\n",
    "            'next_word.is_surname_indicator': next_word in surname_indicators,\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def process_name_bio(row, reversed=False):\n",
    "    if reversed:\n",
    "        segments = ['LAST', 'FIRST', 'MIDDLE']\n",
    "        full_name = row['last_name'] + ', ' + ' '.join([word for word in [row[f'{x.lower()}_name'] for x in segments[1:]] if word])\n",
    "\n",
    "        tokens = full_name.split()\n",
    "        labels = []\n",
    "        \n",
    "        for name_segment in segments:\n",
    "            segment_words = row[f'{name_segment.lower()}_name'].split()\n",
    "            if len(segment_words) == 0:\n",
    "                continue\n",
    "            elif len(segment_words) == 1:\n",
    "                labels.append(f'B-{name_segment}')\n",
    "            else:\n",
    "                labels.extend([f'B-{name_segment}'] + [f'I-{name_segment}'] * (len(segment_words) - 1))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        segments = ['FIRST', 'MIDDLE', 'LAST']\n",
    "        full_name = ' '.join([word for word in [row[f'{x.lower()}_name'] for x in segments] if word])\n",
    "        tokens = full_name.split()\n",
    "        labels = []\n",
    "        \n",
    "        for name_segment in segments:\n",
    "            segment_words = row[f'{name_segment.lower()}_name'].split()\n",
    "            if len(segment_words) == 0:\n",
    "                continue\n",
    "            elif len(segment_words) == 1:\n",
    "                labels.append(f'B-{name_segment}')\n",
    "            else:\n",
    "                labels.extend([f'B-{name_segment}'] + [f'I-{name_segment}'] * (len(segment_words) - 1))\n",
    "        \n",
    "    return {\n",
    "        'full_name': full_name,\n",
    "        'tokens': tokens,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply the processing function to create a new dataframe with BIO labels\n",
    "bio_data = df.apply(lambda row: process_name_bio(row, reversed=random.choice([True, False])), axis=1).tolist()\n",
    "bio_df = pd.DataFrame(bio_data)\n",
    "\n",
    "# Add features to the DataFrame\n",
    "bio_df['features'] = bio_df.apply(lambda row: [extract_features(row['tokens'], i) for i in range(len(row['tokens']))], axis=1)\n",
    "\n",
    "# Prepare data for Naive Bayes\n",
    "X = [item for sublist in bio_df['features'].tolist() for item in sublist]\n",
    "y = [item for sublist in bio_df['labels'].tolist() for item in sublist]\n",
    "\n",
    "# Convert feature dictionaries to vectors\n",
    "vec = DictVectorizer(sparse=False)\n",
    "X_vec = vec.fit_transform(X)\n",
    "\n",
    "# Convert labels to integer encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Model Performance:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# # Function to predict on new data\n",
    "# def predict_name_parts_nb(name, nb_model, vec, le):\n",
    "#     tokens = name.split()\n",
    "#     features = extract_features(tokens)\n",
    "#     X_new = vec.transform(features)\n",
    "#     y_pred = nb_model.predict(X_new)\n",
    "#     labels = le.inverse_transform(y_pred)\n",
    "#     return list(zip(tokens, labels))\n",
    "\n",
    "# # Example usage\n",
    "# sample_name = 'JUAN DELA CRUZ SANTOS'\n",
    "# predicted_parts = predict_name_parts_nb(sample_name, nb, vec, le)\n",
    "# print(f\"\\nPrediction for '{sample_name}':\")\n",
    "# for token, label in predicted_parts:\n",
    "#     print(f\"{token}: {label}\")\n",
    "\n",
    "# Get feature importance\n",
    "feature_importances = nb.feature_log_prob_\n",
    "sorted_features = sorted(\n",
    "    zip(vec.get_feature_names(), feature_importances.max(axis=0)),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "for feature, importance in sorted_features[:10]:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
